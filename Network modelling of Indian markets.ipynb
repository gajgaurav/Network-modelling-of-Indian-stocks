{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eec01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_above_diagonal(matrix1, matrix2):\n",
    "    # Check if matrices are square and have the same order\n",
    "    order1 = len(matrix1)\n",
    "    order2 = len(matrix2)\n",
    "    if order1 != len(matrix1[0]) or order2 != len(matrix2[0]) or order1 != order2:\n",
    "        raise ValueError(\"Matrices must be square and have the same order.\")\n",
    "\n",
    "    # Initialize sum to 0\n",
    "    above_diagonal_sum = 0\n",
    "\n",
    "    # Iterate through each row\n",
    "    for i in range(order1):\n",
    "        # Iterate through each column, starting from the diagonal element\n",
    "        for j in range(i + 1, order1):\n",
    "            # Sum upper triangular elements\n",
    "            above_diagonal_sum += matrix1[i][j] + matrix2[i][j]\n",
    "\n",
    "    return above_diagonal_sum\n",
    "\n",
    "def above_diagonal_sameness_metric(matrix1, matrix2):\n",
    "    # Check if matrices are square and have the same order\n",
    "    order1 = len(matrix1)\n",
    "    order2 = len(matrix2)\n",
    "    if order1 != len(matrix1[0]) or order2 != len(matrix2[0]) or order1 != order2:\n",
    "        raise ValueError(\"Matrices must be square and have the same order.\")\n",
    "\n",
    "    # Initialize count to 0\n",
    "    sameness_count = 0\n",
    "\n",
    "    # Iterate through each row\n",
    "    for i in range(order1):\n",
    "        # Iterate through each column, starting from the diagonal element\n",
    "        for j in range(i + 1, order1):\n",
    "            # Check if upper triangular elements are the same\n",
    "            if (matrix1[i][j] + matrix2[i][j]) == 0:\n",
    "                sameness_count += 1 - 1\n",
    "            else:\n",
    "                sameness_count += 1 - 0\n",
    "    \n",
    "    return (sameness_count)\n",
    "\n",
    "# correlation coefficient between the two matrices\n",
    "\n",
    "def information_linkage_coefficient(matrix1, matrix2):\n",
    "    term1 = sum_above_diagonal(matrix1, matrix2)\n",
    "    term2 = above_diagonal_sameness_metric(matrix1, matrix2)\n",
    "    \n",
    "    return (term1 - term2)/term2\n",
    "\n",
    "\n",
    "def above_diagonal_sum_general(matrices):\n",
    "    # Check if matrices is not empty\n",
    "    if not matrices:\n",
    "        raise ValueError(\"Input list of matrices is empty\")\n",
    "\n",
    "    # Check if all matrices are of the same shape\n",
    "    shapes = [np.shape(matrix) for matrix in matrices]\n",
    "    if not all(shape == shapes[0] for shape in shapes):\n",
    "        raise ValueError(\"All matrices must have the same shape\")\n",
    "    \n",
    "    order1 = shapes[0][0]\n",
    "    \n",
    "    \n",
    "\n",
    "    # Initialize the sum matrix with zeros\n",
    "    above_diagonal_sum = 0\n",
    "\n",
    "    # Add the above diagonal elements of each matrix\n",
    "    for matrix in matrices:\n",
    "        for i in range(order1):\n",
    "            for j in range(i + 1, order1):\n",
    "                above_diagonal_sum += matrix[i][j]\n",
    "                \n",
    "\n",
    "    return above_diagonal_sum\n",
    "\n",
    "def sum_matrices(matrices):\n",
    "    \n",
    "    if not matrices:\n",
    "        raise ValueError(\"List of matrices is empty.\")\n",
    "\n",
    "    result_matrix = np.zeros_like(matrices[0])  # Initialize result matrix with zeros\n",
    "\n",
    "    for matrix in matrices:\n",
    "        result_matrix += matrix\n",
    "\n",
    "    return result_matrix\n",
    "\n",
    "def above_diagonal_sameness_metric_general(matrices):\n",
    "    # Check if matrices is not empty\n",
    "    if not matrices:\n",
    "        raise ValueError(\"Input list of matrices is empty\")\n",
    "\n",
    "    # Check if all matrices are of the same shape\n",
    "    shapes = [np.shape(matrix) for matrix in matrices]\n",
    "    if not all(shape == shapes[0] for shape in shapes):\n",
    "        raise ValueError(\"All matrices must have the same shape\")\n",
    "    \n",
    "    order1 = shapes[0][0]\n",
    "\n",
    "    # Initialize count to 0\n",
    "    sameness_count = 0\n",
    "\n",
    "    # Iterate through each row\n",
    "    for i in range(order1):\n",
    "        # Iterate through each column, starting from the diagonal element\n",
    "        for j in range(i + 1, order1):\n",
    "            # Check if above diagonal elements are both zero\n",
    "            if sum_matrices(matrices)[i][j] == 0:\n",
    "                sameness_count += 1 - 1\n",
    "            else:\n",
    "                sameness_count += 1 - 0\n",
    "    \n",
    "    return (sameness_count)\n",
    "\n",
    "def interlayer_correlation(matrices):\n",
    "    term1 = above_diagonal_sum_general(matrices)\n",
    "    term2 = above_diagonal_sameness_metric_general(matrices)\n",
    "    n_layers = len(matrices)\n",
    "    \n",
    "    return (term1 - term2)/((n_layers - 1)*term2)\n",
    "\n",
    "def embed_time_series(time_series, embedding_dimension, embedding_delay):\n",
    "    \n",
    "    n = len(time_series)\n",
    "    embedded_matrix = np.zeros((n - (embedding_dimension - 1) * embedding_delay, embedding_dimension))\n",
    "\n",
    "    for i in range(embedding_dimension):\n",
    "        embedded_matrix[:, i] = time_series[i * embedding_delay : i * embedding_delay + len(embedded_matrix)]\n",
    "\n",
    "    return embedded_matrix\n",
    "\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    " \n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def create_closeness_matrix(embedded_time_series, percentage_threshold):\n",
    "    \n",
    "    n = embedded_time_series.shape[0]\n",
    "    closeness_matrix = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    total_points = n * (n - 1) // 2  # Total number of unique pairs\n",
    "\n",
    "    # Calculate the threshold distance based on the percentage\n",
    "    sorted_distances = np.sort([euclidean_distance(embedded_time_series[i], embedded_time_series[j])\n",
    "                                for i in range(n) for j in range(i + 1, n)])\n",
    "    threshold_distance_index = int(percentage_threshold * total_points / 100)\n",
    "    threshold_distance = sorted_distances[threshold_distance_index]\n",
    "\n",
    "    # Set edges based on the threshold distance\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            distance = euclidean_distance(embedded_time_series[i], embedded_time_series[j])\n",
    "            closeness_matrix[i, j] = closeness_matrix[j, i] = 1 if distance < threshold_distance else 0\n",
    "\n",
    "    return closeness_matrix\n",
    "\n",
    "def windows(embedded_series, window_length, sliding_step):\n",
    "    windows = []\n",
    "    num_windows = int(np.floor((len(embedded_series) - window_length)/sliding_step + 1))\n",
    "    for i in range(num_windows):\n",
    "        window = embedded_series[i * (sliding_step) :i * (sliding_step) + window_length]\n",
    "        windows.append(window)\n",
    "    return windows\n",
    "\n",
    "def RecurrencePlot(matrix, name):\n",
    "    plt.matshow(matrix)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Adjacency Matrix \" + name)\n",
    "    plt.xlabel(\"Node (i)\")\n",
    "    plt.ylabel(\"Node (j)\")\n",
    "    plt.show()\n",
    "\n",
    "def time_delayed_correlation(dataframe, series1, series2, embedding_dimension, embedding_delay, \n",
    "                             window_length, sliding_step, percentage_threshold, correlation_delay):\n",
    "    \n",
    "    if len(series1) != len(series2):\n",
    "        return('time series are of different sizes')\n",
    "    else:\n",
    "    \n",
    "        series1_embedded = embed_time_series(series1, embedding_dimension, embedding_delay) \n",
    "        series2_embedded = embed_time_series(series2 , embedding_dimension, embedding_delay) \n",
    "\n",
    "        series1_windows = windows(series1_embedded, window_length, sliding_step)\n",
    "        series2_windows = windows(series2_embedded, window_length, sliding_step)\n",
    "\n",
    "        corr_df = pd.DataFrame(columns = ['date', 'delayed_correlation'])\n",
    "\n",
    "        for i in range(abs(correlation_delay), len(series1_windows) - abs(correlation_delay) ):\n",
    "            m1 = create_closeness_matrix(series1_windows[i], percentage_threshold)\n",
    "            m2 = create_closeness_matrix(series2_windows[i + correlation_delay], percentage_threshold)\n",
    "    \n",
    "            window_index1 = dataframe.index[series1 == series1_windows[i][0][0]].tolist()\n",
    "            date = dataframe['Date'][window_index1[0]]\n",
    "            correlation1 = interlayer_correlation([m1, m2])\n",
    "            print(date, correlation1)\n",
    "    \n",
    "            corr_df.loc[len(corr_df)] = [date, correlation1]\n",
    "        \n",
    "        return corr_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stock data for RNs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97122e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AXISBANK.NS'] = df['AXISBANK.NS'].interpolate()\n",
    "testing_df = df[['Date','HDFCBANK.NS', 'AXISBANK.NS', 'year']]\n",
    "new_df = testing_df.copy()\n",
    "for i in range(1, len(testing_df)):\n",
    "    new_df['HDFCBANK.NS'][i] = math.log(testing_df['HDFCBANK.NS'][i]/testing_df['HDFCBANK.NS'][i-1])\n",
    "    new_df['AXISBANK.NS'][i] = math.log(testing_df['AXISBANK.NS'][i]/testing_df['AXISBANK.NS'][i-1])\n",
    "    \n",
    "new_df = new_df.iloc[1:]\n",
    "new_df = new_df[new_df['year'] >= 2017]\n",
    "\n",
    "hdfc_embedded = embed_time_series(new_df['HDFCBANK.NS'], 8, 5) \n",
    "axis_embedded = embed_time_series(new_df['AXISBANK.NS'] , 8, 5) \n",
    "\n",
    "hdfc_windows = windows(hdfc_embedded, 250, 5)\n",
    "axis_windows = windows(axis_embedded, 250, 5)\n",
    "\n",
    "correlation_df = pd.DataFrame(columns = ['date', 'correlation'])\n",
    "\n",
    "for i in range(len(hdfc_windows)):\n",
    "    m1 = create_closeness_matrix(hdfc_windows[i], 5)\n",
    "    m2 = create_closeness_matrix(axis_windows[i], 5)\n",
    "    \n",
    "    window_index = new_df.index[new_df['HDFCBANK.NS'] == hdfc_windows[i][0][0]].tolist()\n",
    "    date = new_df['Date'][window_index[0]]\n",
    "    correlation = interlayer_correlation([m1, m2])\n",
    "    print(date, correlation)\n",
    "    \n",
    "    correlation_df.loc[len(correlation_df)] = [date, correlation]\n",
    "    \n",
    "\n",
    "for i in range(len(correlation_df)):\n",
    "    correlation_df['date'][i] = correlation_df['date'][i].split()[0].split('-')[0] + '-' + correlation_df['date'][i].split()[0].split('-')[1]\n",
    "    \n",
    "correlation_df['date'] = pd.to_datetime(correlation_df['date'])\n",
    "\n",
    "# Plotting the elements of the list\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(correlation_df['date'], correlation_df['correlation'] , marker = 'o', linestyle = '-')\n",
    "plt.title('correlation over time (HDFC AND AXIS BANK)')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "#plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.xlabel('time period')\n",
    "plt.ylabel('correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.plot(correlation_df['date'], correlation_df['correlation'] , marker = 'o', linestyle = '-')\n",
    "plt.title('correlation over time (HDFC AND AXIS BANK)')\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "#plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.xlabel('time period')\n",
    "plt.ylabel('correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90b800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
